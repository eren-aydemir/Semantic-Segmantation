{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import random\n",
    "import numpy as np\n",
    "import os.path\n",
    "import scipy.misc\n",
    "import shutil\n",
    "import zipfile\n",
    "import time\n",
    "import tensorflow as tf\n",
    "from glob import glob\n",
    "from urllib.request import urlretrieve\n",
    "from tqdm import tqdm\n",
    "import helper\n",
    "\n",
    "def load_vgg(sess, vgg_path):\n",
    "    \"\"\"\n",
    "    Load Pretrained VGG Model into TensorFlow.\n",
    "    :param sess: TensorFlow Session\n",
    "    :param vgg_path: Path to vgg folder, containing \"variables/\" and \"saved_model.pb\"\n",
    "    :return: Tuple of Tensors from VGG model (image_input, keep_prob, layer3_out, layer4_out, layer7_out)\n",
    "    \"\"\"\n",
    "    # TODO: Implement function\n",
    "    #   Use tf.saved_model.loader.load to load the model and weights\n",
    "    vgg_tag = 'vgg16'\n",
    "    vgg_input_tensor_name = 'image_input:0'\n",
    "    vgg_keep_prob_tensor_name = 'keep_prob:0'\n",
    "    vgg_layer3_out_tensor_name = 'layer3_out:0'\n",
    "    vgg_layer4_out_tensor_name = 'layer4_out:0'\n",
    "    vgg_layer7_out_tensor_name = 'layer7_out:0'\n",
    "\n",
    "    model = tf.saved_model.loader.load(sess, [vgg_tag], vgg_path)\n",
    "\n",
    "    graph = tf.get_default_graph()\n",
    "    image_input = graph.get_tensor_by_name(vgg_input_tensor_name)\n",
    "    keep_prob = graph.get_tensor_by_name(vgg_keep_prob_tensor_name)\n",
    "    layer3 = graph.get_tensor_by_name(vgg_layer3_out_tensor_name)\n",
    "    layer4 = graph.get_tensor_by_name(vgg_layer4_out_tensor_name)\n",
    "    layer7 = graph.get_tensor_by_name(vgg_layer7_out_tensor_name)\n",
    "    \n",
    "    return image_input, keep_prob, layer3, layer4, layer7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def layers(vgg_layer3_out, vgg_layer4_out, vgg_layer7_out, num_classes):\n",
    "    \"\"\"\n",
    "    Create the layers for a fully convolutional network.  Build skip-layers using the vgg layers.\n",
    "    :param vgg_layer7_out: TF Tensor for VGG Layer 3 output\n",
    "    :param vgg_layer4_out: TF Tensor for VGG Layer 4 output\n",
    "    :param vgg_layer3_out: TF Tensor for VGG Layer 7 output\n",
    "    :param num_classes: Number of classes to classify\n",
    "    :return: The Tensor for the last layer of output\n",
    "    \"\"\"\n",
    "    # TODO: Implement function\n",
    "    # 1x1 convolution of vgg layer 7\n",
    "    layer7a_out = tf.layers.conv2d(vgg_layer7_out, num_classes, 1, \n",
    "                                   padding= 'same', \n",
    "                                   kernel_initializer= tf.random_normal_initializer(stddev=0.01),\n",
    "                                   kernel_regularizer= tf.contrib.layers.l2_regularizer(1e-3))\n",
    "    # upsampling\n",
    "    layer4a_in1 = tf.layers.conv2d_transpose(layer7a_out, num_classes, 4, \n",
    "                                             strides= (2, 2), \n",
    "                                             padding= 'same', \n",
    "                                             kernel_initializer= tf.random_normal_initializer(stddev=0.01), \n",
    "                                             kernel_regularizer= tf.contrib.layers.l2_regularizer(1e-3))\n",
    "    # 1x1 convolution of vgg layer 4\n",
    "    layer4a_in2 = tf.layers.conv2d(vgg_layer4_out, num_classes, 1, \n",
    "                                   padding= 'same', \n",
    "                                   kernel_initializer= tf.random_normal_initializer(stddev=0.01), \n",
    "                                   kernel_regularizer= tf.contrib.layers.l2_regularizer(1e-3))\n",
    "    # skip connection (element-wise addition)\n",
    "    layer4a_out = tf.add(layer4a_in1, layer4a_in2)\n",
    "    # upsampling\n",
    "    layer3a_in1 = tf.layers.conv2d_transpose(layer4a_out, num_classes, 4,  \n",
    "                                             strides= (2, 2), \n",
    "                                             padding= 'same', \n",
    "                                             kernel_initializer= tf.random_normal_initializer(stddev=0.01), \n",
    "                                             kernel_regularizer= tf.contrib.layers.l2_regularizer(1e-3))\n",
    "    # 1x1 convolution of vgg layer 3\n",
    "    layer3a_in2 = tf.layers.conv2d(vgg_layer3_out, num_classes, 1, \n",
    "                                   padding= 'same', \n",
    "                                   kernel_initializer= tf.random_normal_initializer(stddev=0.01), \n",
    "                                   kernel_regularizer= tf.contrib.layers.l2_regularizer(1e-3))\n",
    "    # skip connection (element-wise addition)\n",
    "    layer3a_out = tf.add(layer3a_in1, layer3a_in2)\n",
    "    # upsampling\n",
    "    nn_last_layer = tf.layers.conv2d_transpose(layer3a_out, num_classes, 16,  \n",
    "                                               strides= (8, 8), \n",
    "                                               padding= 'same', \n",
    "                                               kernel_initializer= tf.random_normal_initializer(stddev=0.01), \n",
    "                                               kernel_regularizer= tf.contrib.layers.l2_regularizer(1e-3))\n",
    "    return nn_last_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def optimize(nn_last_layer, correct_label, learning_rate, num_classes):\n",
    "    \"\"\"\n",
    "    Build the TensorFLow loss and optimizer operations.\n",
    "    :param nn_last_layer: TF Tensor of the last layer in the neural network\n",
    "    :param correct_label: TF Placeholder for the correct label image\n",
    "    :param learning_rate: TF Placeholder for the learning rate\n",
    "    :param num_classes: Number of classes to classify\n",
    "    :return: Tuple of (logits, train_op, cross_entropy_loss)\n",
    "    \"\"\"\n",
    "    # TODO: Implement function\n",
    "    # make logits a 2D tensor where each row represents a pixel and each column a class\n",
    "    logits = tf.reshape(nn_last_layer, (-1, num_classes))\n",
    "    correct_label = tf.reshape(correct_label, (-1,num_classes))\n",
    "    # define loss function\n",
    "    cross_entropy_loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits= logits, labels= correct_label))\n",
    "    # define training operation\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate= learning_rate)\n",
    "    train_op = optimizer.minimize(cross_entropy_loss)\n",
    "\n",
    "    return logits, train_op, cross_entropy_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from b'./data/vgg/variables/variables'\n"
     ]
    }
   ],
   "source": [
    "num_classes = 2\n",
    "image_shape = (160, 576)\n",
    "model_path = 'model/model_v1.ckpt'\n",
    "data_dir = './data'\n",
    "vgg_path = os.path.join(data_dir, 'vgg')\n",
    "\n",
    "with tf.Session() as sess:\n",
    "        \n",
    "    # TF placeholders\n",
    "    correct_label = tf.placeholder(tf.int32, [None, None, None, num_classes], name='correct_label')\n",
    "    learning_rate = tf.placeholder(tf.float32, name='learning_rate')\n",
    "\n",
    "    input_image, keep_prob, vgg_layer3_out, vgg_layer4_out, vgg_layer7_out = load_vgg(sess, vgg_path)\n",
    "\n",
    "    nn_last_layer = layers(vgg_layer3_out, vgg_layer4_out, vgg_layer7_out, num_classes)\n",
    "\n",
    "    logits, train_op, cross_entropy_loss = optimize(nn_last_layer, correct_label, learning_rate, num_classes)\n",
    "\n",
    "    #init = tf.global_variables_initializer()\n",
    "    saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_test_output(sess, logits, keep_prob, image_pl, data_folder, image_shape):\n",
    "    print('1')\n",
    "    for image_file in glob(os.path.join(data_folder, 'image_2', '*.png')):\n",
    "        image = scipy.misc.imresize(scipy.misc.imread(image_file), image_shape)\n",
    "        print('2')\n",
    "        im_softmax = sess.run(\n",
    "            [tf.nn.softmax(logits)],\n",
    "            {keep_prob: 1.0, image_pl: [image]})\n",
    "        print('3')\n",
    "        im_softmax = im_softmax[0][:, 1].reshape(image_shape[0], image_shape[1])\n",
    "        segmentation = (im_softmax > 0.5).reshape(image_shape[0], image_shape[1], 1)\n",
    "        mask = np.dot(segmentation, np.array([[0, 255, 0, 127]]))\n",
    "        mask = scipy.misc.toimage(mask, mode=\"RGBA\")\n",
    "        street_im = scipy.misc.toimage(image)\n",
    "        street_im.paste(mask, box=None, mask=mask)\n",
    "\n",
    "        yield os.path.basename(image_file), np.array(street_im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from model/model_v1.ckpt\n",
      "Model restored from file: model/model_v1.ckpt\n",
      "1\n",
      "2\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Attempted to use a closed Session.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-ec2aefb3945f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m     sess, logits, keep_prob, input_image, os.path.join(data_dir, 'data_road/testing'), image_shape)\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mimage_outputs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmisc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimsave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-13-0127de5a907c>\u001b[0m in \u001b[0;36mgen_test_output\u001b[0;34m(sess, logits, keep_prob, image_pl, data_folder, image_shape)\u001b[0m\n\u001b[1;32m      6\u001b[0m         im_softmax = sess.run(\n\u001b[1;32m      7\u001b[0m             \u001b[0;34m[\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m             {keep_prob: 1.0, image_pl: [image]})\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'3'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mim_softmax\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mim_softmax\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/darkflow/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    893\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 895\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    896\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/darkflow/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1049\u001b[0m     \u001b[0;31m# Check session.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1050\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_closed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1051\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Attempted to use a closed Session.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mversion\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m       raise RuntimeError('The Session graph is empty.  Add operations to the '\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Attempted to use a closed Session."
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    # Initialize variables\n",
    "    #sess.run(init)\n",
    "\n",
    "    # Restore model weights from previously saved model\n",
    "    saver.restore(sess, model_path)\n",
    "    print(\"Model restored from file: %s\" % model_path)\n",
    "    \n",
    "    image_outputs = gen_test_output(\n",
    "    sess, logits, keep_prob, input_image, os.path.join(data_dir, 'data_road/testing'), image_shape)\n",
    "\n",
    "for name, image in image_outputs:\n",
    "    scipy.misc.imsave(os.path.join(output_dir, name), image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
